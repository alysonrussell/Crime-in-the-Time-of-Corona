{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime in the time of Corona - Create DB from raw CSV tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add dependencies: Pandas\n",
    "import pandas as pd\n",
    "import os # needed to use the os.path.join method to load the files\n",
    "from sqlalchemy import create_engine # for integrating with PostgreSQL\n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incidents: Load raw csv, create dataframe and clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV Files into a dataframes.\n",
    "incidents_raw_df = pd.read_csv(\"../Resources - MPD Data/incidentTableClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Review the incidents table fields and counts of each field.\n",
    "incidents_raw_df.info()\n",
    "# 1788 records. Removed MP20009253 from CSV due to very incomplete record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Number field for uniqueness. Its our primary field\n",
    "incidents_raw_df.Number.value_counts(sort=True, dropna=True, ascending=False, bins=None)\n",
    "# Results show 1660 unique values meaning 127 are possible duplicates.\n",
    "# Looks like Case Number duplication is valid due to multiple offenses under same case.\n",
    "# Need to create a primary unique field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a primary unique field: Number plus offenseCode. \n",
    "# Call it CID for Case Id\n",
    "incidents_raw_df[\"CID\"] = incidents_raw_df[\"Number\"] + ' - ' + incidents_raw_df[\"offenseCode\"] \n",
    "incidents_raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uniqueness of new combined field\n",
    "incidents_raw_df.CID.value_counts(sort=True, dropna=True, ascending=False, bins=None) \n",
    "# Visual review of remaining double entries shows they are in fact duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Duplicate Case IDs. Then check counts again.\n",
    "incidents_raw_df.drop_duplicates(subset =\"CID\", keep = False, inplace = True)\n",
    "incidents_raw_df.CID.value_counts(sort=True, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to CID.  If it works, we have unique values for our CID field. woohoo!\n",
    "incidents_raw_df.set_index('CID',inplace=True)\n",
    "incidents_raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much data is left in our dataframe?\n",
    "incidents_raw_df.info()\n",
    "# Looks like 1778 rows, so we eliminated 10 records.  Lots of work for a unique primary key, but necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ok. now we review and clean remaining fields in Incidents table. \n",
    "#  Start with the date field. Create a new date field stripped to date without time.\n",
    "incidents_raw_df[\"dateIncident\"] = pd.to_datetime(incidents_raw_df[\"dateReported\"]).apply(lambda x: x.date())\n",
    "incidents_raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new week field so we can do stats of crime types over time by week.\n",
    "incidents_raw_df['weekNumber'] = pd.to_datetime(incidents_raw_df['dateReported']).dt.week\n",
    "\n",
    "# This works, but since our data starts in 2019, we have five weeks with numbers over 40. Starting with Week 47 with blank week.\n",
    "incidents_raw_df.weekNumber.value_counts(sort=True, dropna=True, ascending=False, bins=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to fix to make weekNumber column useful for linear regression analysis?\n",
    "#  Add six to each week number so that the first six slots in the week order can be allocated to 2019\n",
    "incidents_raw_df['weekNumber']= incidents_raw_df['weekNumber'] + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now replace the high values for 2019 weeks with proper lower numbers.\n",
    "incidents_raw_df[\"weekNumber\"].replace({53:1,54:2,55:3,56:4,57:5,58:6}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the weekNumber field tally look now? Sweet!\n",
    "incidents_raw_df.weekNumber.value_counts(sort=True, ascending=False, bins=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we look at our offense codes. \n",
    "incidents_raw_df.offenseCode.value_counts(sort=True, ascending=False)\n",
    "# Need a subject matter expert. This could be ok. Or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now export the cleaned Incidents table.\n",
    "\n",
    "# Crimes to CSV\n",
    "#cleaned_incidents = os.path.join(\"CleanData\", \"Cleaned_Incidents.csv\")\n",
    "cleaned_incidents = \"../Resources/CleanedData/Cleaned_Incidents.csv\"\n",
    "incidents_raw_df.to_csv(cleaned_incidents, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FBI Crime Data: Load raw csv, create dataframe and clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FBICrimes Load and Clean the 1980 to 2018 csv data into a dataframe\n",
    "FBICrimes_df =  pd.read_csv(\"../Resources/est_crimes_1980_2018_FBI_UCRdata.csv\")\n",
    "FBICrimes_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data looks clean. No obvious transformations needed. Ourarget of aggravated assault has a full row counts of 1974.\n",
    "FBICrimes_df.info(3)\n",
    "FBICrimes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploratory Data Analysis of FBI Crime Data.\n",
    "#for year in FBICrimes_df:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### National Unemployment Data,1980- 2018. Load and Clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Unemployment Data, 1980-2018. Load and Clean.\n",
    "Unemployment_df =  pd.read_csv(\"../Resources/unemployment_by_state_1980_2018_BLSdata.csv\")\n",
    "Unemployment_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data looks clean. No obvious transformations needed. Our target of aggravated assault has a full row counts of 1974.\n",
    "Unemployment_df.info(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suspects: Load raw csv, create dataframe and clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the suspects csv into a dataframe.\n",
    "suspects_raw_df = pd.read_csv(\"../Resources - MPD Data/suspectTable.csv\")\n",
    "suspects_raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the suspects table structure\n",
    "suspects_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Victims: Load raw csv, create dataframe and clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the victims csv into a dataframe.\n",
    "victims_raw_df = pd.read_csv(\"../Resources - MPD Data/victimTable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the suspects table structure\n",
    "victims_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
